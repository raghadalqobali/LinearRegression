# -*- coding: utf-8 -*-
"""LinearReg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18sTLrEdlmnfw387W6Z2dauz-BAj-M1ju
"""

import numpy.matlib 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""![Screen%20Shot%202022-02-26%20at%207.06.47%20PM.png](attachment:Screen%20Shot%202022-02-26%20at%207.06.47%20PM.png)"""

dataset=pd.read_csv('dataset_q2_q4.csv')

dataset

dataset.dtypes

y=dataset['y_label']
X=dataset.drop('y_label', axis=1)

print(X.shape)
print(y.shape)

X.head()

X=np.array(X)
y=np.array(y)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=10) # split dataset

def fit1_func(X,y,lr=0.002200000000000000000000,epochs=3):
    #define theta
    theta0=1.
    theta1=1.
    theta2=1.
    theta3=1.
    #define x1,x2,x3
    x1=X[:,0]
    x2=X[:,1]
    x3=X[:,2]
    m=y.size
    losses=[]
        
    for i in range(epochs):
        
        
        
        y_hat= ((3*theta1*square(x1)) + (theta2*cube(x2)) - (theta3*cube(x2)) + (theta2*theta3*cube(x3)) + theta0)
        loss=np.sum(square(y_hat - y))/(2*m)
        losses.append(loss)
        
        theta0_grad=np.sum(y_hat-y)/m
        theta1_grad=np.matmul((3*x1**2),(y_hat-y))/m
        theta2_grad=np.matmul((x2**3)+(theta3*x3**3),(y_hat-y))/m
        theta3_grad=np.matmul((-x2**3)+(theta2*x3**3),(y_hat-y))/m
        
        
        theta0=theta0-lr*theta0_grad
        theta1=theta0-lr*theta1_grad
        theta2=theta0-lr*theta2_grad
        theta3=theta0-lr*theta3_grad
        

    print("number of losses:",len(losses))
    print("The loss: " ,loss)
    print(m)
    print()
    print("y_hat:")
    print(y_hat[:10])
      
    plt.plot(list(range(epochs)),losses)
    return theta0, theta1, theta2, theta3

theta0, theta1, theta2, theta3 =fit1_func(x_train,y_train)
print()
print()
print()
print("y_correct:")
print(y_test[:10])
print()
print("thetas: ",theta0,theta1,theta2,theta3)

def square(num):
    return num*num

def cube(num):
    return num*num*num

def fit2_func(X,Y,lr=0.000222000000000000002,epochs=3):
    
    #define theta
    theta0=0.
    theta1=0.
    theta2=0.
    theta3=0.
    #define x1,x2,x3
    #x1=X[:,0]
    #x2=X[:,1]
    #x3=X[:,2]
    m=Y.size
    losses=[]
    for i in range(epochs):
        loss=0.
        theta0_grad=1
        theta1_grad=1
        theta2_grad=1
        theta3_grad=1
        
        for x,y in zip(X,Y):
            x1,x2,x3=x
            y_hat= (3*theta1*square(x1)) + (theta2*cube(x2)) - (theta3*cube(x2)) + (theta2*theta3*cube(x3)) + theta0
            loss += square((y_hat - y))
            theta0_grad=theta0_grad+(y_hat-y)*1
            theta1_grad=theta1_grad+(y_hat-y)*3*square(x1)
            theta2_grad=theta2_grad+(y_hat-y)*cube(x2)+theta3*cube(x3)
            theta3_grad=theta0_grad+(y_hat-y)*(cube(-x2)+theta2*cube(x3))
        losses.append(loss/m)
        theta0_grad=theta0_grad/m
        theta1_grad=theta1_grad/m
        theta2_grad=theta2_grad/m
        theta3_grad=theta3_grad/m
        
        
        theta0=theta0-lr*theta0_grad
        theta1=theta0-lr*theta1_grad
        theta2=theta0-lr*theta2_grad
        theta3=theta0-lr*theta3_grad
        
        loss=loss/2*m
    print(len(losses))
    print(loss)
    
    
    plt.plot(list(range(epochs)),losses)
    return theta0, theta1, theta2, theta3

theta0, theta1, theta2, theta3 =fit2_func(x_train,y_train)
print()
print()
print()
print("thetas: ",theta0,theta1,theta2,theta3)